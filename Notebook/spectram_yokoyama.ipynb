{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import scipy\n",
    "from scipy import signal\n",
    "from numpy.fft import fft\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.initializers import he_normal\n",
    "from tensorflow.python.keras.utils.vis_utils import plot_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(font='Yu Gothic')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import gc\n",
    "\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \".\"\n",
    "\n",
    "def norm(x):\n",
    "    x = np.sqrt(np.square(x[:, :, 0]) + np.square(x[:, :, 1]) + np.square(x[:, :, 2]))\n",
    "    return x.reshape([-1, 500])\n",
    "def spectrogtam(x):\n",
    "    nfft = 64\n",
    "    overlap = nfft - 1\n",
    "    \n",
    "    x = scipy.signal.spectrogram(x, fs=100, nfft=nfft, noverlap=overlap, nperseg=nfft)[2]\n",
    "    x = (x - x.mean(axis=1, keepdims=True)) / x.std(axis=1, keepdims=True)\n",
    "    return x\n",
    "def load_npy(sensor=\"Acc\", kind=\"train\"):\n",
    "    x = np.load(file_path + \"/\" + kind + \"/\" + kind + \"_Hips/\" + kind + \"_Hips_Glo_\" + sensor + \"_ver3.npy\")\n",
    "    x = norm(x)\n",
    "    x = np.apply_along_axis(spectrogtam, 1, x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(sensor):\n",
    "    return np.load(\"save/train_Hips_\" + sensor + \".npy\")\n",
    "\n",
    "X_train = load(\"Acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28685,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern_file = np.load(\"bunseki/validation_pattern2.npy\").reshape([-1]) #パターンファイルのパス入れてくれ\n",
    "pattern_file.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28685,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_label = np.load(file_path + \"/validation/validation_Hips/validation_Hips_Label.npy\")[:, 0].reshape([-1])\n",
    "val_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(sensor):\n",
    "    return load_npy(sensor, \"validation\")\n",
    "\n",
    "X_val = load_npy(\"Acc\", \"validation\")\n",
    "X_val = X_val.reshape([-1, 1, vaildation_Hips_Acc.shape[1], vaildation_Hips_Acc.shape[2], 1])\n",
    "\n",
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((195491, 1, 33, 437, 1), (28685, 1, 33, 437, 1))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.round(X_train, 5)\n",
    "X_val = np.round(X_val, 5)\n",
    "\n",
    "X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5696, 1, 33, 437, 1), (14338, 1, 33, 437, 1), (8651, 1, 33, 437, 1))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_pattern0 = X_val[pattern_file == 0]\n",
    "X_val_pattern1 = X_val[pattern_file == 1]\n",
    "X_val_pattern2 = X_val[pattern_file == 2]\n",
    "\n",
    "X_val_pattern0.shape, X_val_pattern1.shape, X_val_pattern2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separateData(x, y):\n",
    "    pattern = np.zeros(x.shape[0])\n",
    "    for i in range(8):\n",
    "        tmp = np.where(y == i)[0]\n",
    "        pattern[tmp[tmp.shape[0]//10*7:]] = 1\n",
    "        print(tmp)\n",
    "        \n",
    "    x_train = x[pattern == 0]\n",
    "    x_test = x[pattern == 1]\n",
    "    y_train = y[pattern == 0]\n",
    "    y_test = y[pattern == 1]\n",
    "    return x_train, x_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(195490, 1, 33, 437, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label = np.load(file_path + \"/train/train_Hips/train_Hips_Label.npy\")[:, 0].reshape([-1])\n",
    "X_train = np.delete(X_train, 120845, axis=0)\n",
    "train_label = np.delete(train_label, 120845, axis=0)\n",
    "train_label -= 1\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1579   1580   1581 ... 194154 194155 194156]\n",
      "[  1529   1530   1531 ... 194654 194655 194656]\n",
      "[  9374   9375   9376 ... 192718 192719 192720]\n",
      "[     0      1      2 ... 191309 191310 191311]\n",
      "[ 30446  30447  30448 ... 195487 195488 195489]\n",
      "[  9998   9999  10000 ... 187693 187694 187695]\n",
      "[    96     97     98 ... 184260 184261 184262]\n",
      "[  1797   1798   1799 ... 183044 183045 183046]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((136815, 1, 33, 437, 1), (58675, 1, 33, 437, 1))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_val, y_train, y_val = separateData(X_train, train_label)\n",
    "x_train.shape, x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuildModel(input_shape):\n",
    "    input1 = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(64, (3, 3),strides =(1,32), padding='valid', activation='relu', kernel_initializer=he_normal())(input1)\n",
    "    x = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(16, activation='relu')(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    x = layers.Dense(16, activation='relu')(x)\n",
    "    x = layers.Dense(8, activation='softmax')(x)\n",
    "    x = models.Model(inputs=input1, outputs=x)    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 33, 437, 1)]      0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 31, 14, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 31, 14, 32)        18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 15, 7, 32)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 7, 32)         128       \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 15, 7, 64)         18496     \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 15, 7, 32)         18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 7, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 7, 3, 64)          18496     \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 7, 3, 32)          18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 3, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 3, 1, 32)          128       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               12416     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 8)                 136       \n",
      "=================================================================\n",
      "Total params: 117,512\n",
      "Trainable params: 117,256\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = BuildModel(x_train[0, 0].shape)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 136815 samples, validate on 58675 samples\n",
      "Epoch 1/256\n",
      " 82944/136815 [=================>............] - ETA: 3:03 - loss: 1.4693 - accuracy: 0.4095"
     ]
    }
   ],
   "source": [
    "save_folder = \"/3tuduzu/\" #保存ディレクトリを指定(後ろにスラッシュ入れてね)\n",
    "\n",
    "import os\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "\n",
    "cp_cb = tf.keras.callbacks.ModelCheckpoint(filepath=save_folder + \"model_{epoch:02d}-{loss:.2f}-{accuracy:.2f}-{val_loss:.2f}-{val_accuracy:.2f}.hdf5\", \n",
    "                                           monitor='val_loss', verbose=0, save_best_only=True, mode='auto')\n",
    "es_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, verbose=0, mode='auto')\n",
    "history = model.fit(x_train[:, 0], y_train, epochs=256, batch_size=512, \\\n",
    "                    validation_data=(x_val[:, 0], y_val), callbacks=[cp_cb, es_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "# plt.ylim((0, 3.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
