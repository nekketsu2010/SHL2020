{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.initializers import he_normal\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(font='Yu Gothic')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_npy(hold_position):\n",
    "    file_path = \"../Output/train/train_\" + hold_position + \"/train_\" + hold_position\n",
    "    xy_mean = np.load(file_path + \"_glo_laccel_xy_mean.npy\")\n",
    "    xy_var = np.load(file_path + \"_glo_laccel_xy_var.npy\")\n",
    "    z_mean = np.load(file_path + \"_glo_laccel_z_mean.npy\")\n",
    "    z_var = np.load(file_path + \"_glo_laccel_z_var.npy\")\n",
    "    z_skew = np.load(file_path + \"_glo_laccel_z_skew.npy\")\n",
    "    z_kurtosis = np.load(file_path + \"_glo_laccel_z_kurtosis.npy\")\n",
    "    z_lacc_FFT = np.load(file_path + \"_glo_laccel_z_amplitude_frequency_range5Hz.npy\")\n",
    "    z_gyro_FFT = np.load(file_path + \"_glo_gyro_z_ver2_amplitude_frequency_range5Hz.npy\")\n",
    "    result = np.concatenate([xy_mean.reshape([-1, 1]), xy_var.reshape([-1, 1]), z_mean.reshape([-1, 1]), z_var.reshape([-1, 1]), z_skew.reshape([-1, 1]), z_kurtosis.reshape([-1, 1]), z_lacc_FFT, z_gyro_FFT], axis=1)\n",
    "    del xy_mean, xy_var, z_mean, z_var, z_skew, z_kurtosis, z_gyro_FFT\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((195491, 50), (195490, 50))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Bag = load_npy(\"Bag\")\n",
    "train_Hips = load_npy(\"Hips\")\n",
    "train_Hips = np.delete(train_Hips, 120845, 0)\n",
    "train_Torso = load_npy(\"Torso\")\n",
    "train_Hand = load_npy(\"Hand\")\n",
    "\n",
    "train_Bag.shape, train_Hips.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(781963, 50)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.concatenate([train_Bag, train_Hips, train_Torso, train_Hand], axis=0)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(781963, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train = np.load(\"../Data/センサ別npyファイル/train/train_Bag/train_Bag_Label.npy\")[:, 0]\n",
    "Y_train = np.concatenate([Y_train, np.delete(Y_train, 120845, 0), Y_train, Y_train], axis=0)\n",
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_npy(hold_position):\n",
    "    file_path = \"../Output/validation/validation_\" + hold_position + \"/validation_\" + hold_position\n",
    "    xy_mean = np.load(file_path + \"_glo_laccel_xy_mean.npy\")\n",
    "    xy_var = np.load(file_path + \"_glo_laccel_xy_var.npy\")\n",
    "    z_mean = np.load(file_path + \"_glo_laccel_z_mean.npy\")\n",
    "    z_var = np.load(file_path + \"_glo_laccel_z_var.npy\")\n",
    "    z_skew = np.load(file_path + \"_glo_laccel_z_skew.npy\")\n",
    "    z_kurtosis = np.load(file_path + \"_glo_laccel_z_kurtosis.npy\")\n",
    "    z_lacc_FFT = np.load(file_path + \"_glo_laccel_z_amplitude_frequency_range5Hz.npy\")\n",
    "    z_gyro_FFT = np.load(file_path + \"_glo_gyro_z_ver2_amplitude_frequency_range5Hz.npy\")\n",
    "    result = np.concatenate([xy_mean.reshape([-1, 1]), xy_var.reshape([-1, 1]), z_mean.reshape([-1, 1]), z_var.reshape([-1, 1]), z_skew.reshape([-1, 1]), z_kurtosis.reshape([-1, 1]), z_lacc_FFT, z_gyro_FFT], axis=1)\n",
    "    del xy_mean, xy_var, z_mean, z_var, z_skew, z_kurtosis, z_gyro_FFT\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28685, 50)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_Bag = load_npy(\"Bag\")\n",
    "validation_Hips = load_npy(\"Hips\")\n",
    "validation_Torso = load_npy(\"Torso\")\n",
    "validation_Hand = load_npy(\"Hand\")\n",
    "\n",
    "validation_Bag.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114740, 50)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val = np.concatenate([validation_Bag, validation_Hips, validation_Torso, validation_Hand], axis=0)\n",
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114740, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_val = np.load(\"../Data/センサ別npyファイル/validation/validation_Bag/validation_Bag_Label.npy\")[:, 0].reshape([-1, 1])\n",
    "Y_val = np.concatenate([Y_val, Y_val, Y_val, Y_val], axis=0)\n",
    "Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114740, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_val_hold_position = np.zeros((28685*4, 1))\n",
    "for i in range(4):\n",
    "    Y_val_hold_position[28685*i:28685*(i+1)] = i\n",
    "Y_val_hold_position.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114740, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_val = np.concatenate([Y_val, Y_val_hold_position], axis=1)\n",
    "Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train[Y_train >= 5] = 1\n",
    "Y_val[Y_val >= 5] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 標準化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((781963, 50), (114740, 50))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std = StandardScaler()\n",
    "hz_std = StandardScaler()\n",
    "\n",
    "X_train[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] = std.fit_transform(X_train[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]])\n",
    "X_val[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] = std.fit_transform(X_val[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]])\n",
    "\n",
    "X_train[:, [i for i in range(11, 50)]] = hz_std.fit_transform(X_train[:, [i for i in range(11, 50)]])\n",
    "X_val[:, [i for i in range(11, 50)]] = hz_std.transform(X_val[:, [i for i in range(11, 50)]])\n",
    "\n",
    "X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 丸める3より5の方が精度高かった"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.48098, -0.20679,  0.47418, ...,  0.27292,  0.02477, -1.81045],\n",
       "       [ 0.25378, -0.01536,  0.19819, ...,  0.93347,  0.19536,  0.37646],\n",
       "       [-0.21472, -0.21009,  0.12586, ...,  0.40503, -0.24621, -0.02116],\n",
       "       ...,\n",
       "       [-0.35028, -0.2537 ,  0.20789, ..., -1.24637, -0.28993,  0.64154],\n",
       "       [-0.35096, -0.2542 ,  0.09994, ...,  0.73531, -0.27106, -1.34656],\n",
       "       [-0.35675, -0.25241,  0.13752, ...,  1.39587, -0.26832,  0.31019]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.round(X_train, 5)\n",
    "X_val = np.round(X_val, 5)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, array([1., 2., 3., 4.]), array([1., 2., 3., 4.]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.isnan(X_train)), np.sum(np.isnan(Y_train)), np.unique(Y_train), np.unique(Y_val[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = Y_train - 1\n",
    "Y_train = Y_train.astype(np.int32)\n",
    "Y_val[:, 0] = Y_val[:, 0] - 1\n",
    "Y_val = Y_val.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((781963, 1), (114740, 2))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape, Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "        Only computes a batch-wise average of recall.\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "        Only computes a batch-wise average of precision.\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(X_train.shape[1], 1), kernel_initializer=he_normal()))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(4, activation='softmax'))\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy', f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 781963 samples, validate on 114740 samples\n",
      "Epoch 1/128\n",
      "781963/781963 [==============================] - 3s 3us/sample - loss: 1.1609 - accuracy: 0.8952 - f1: 0.5952 - val_loss: 2.0634 - val_accuracy: 0.8316 - val_f1: 0.4304\n",
      "Epoch 2/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.8262 - accuracy: 0.9330 - f1: 0.5122 - val_loss: 1.9445 - val_accuracy: 0.8500 - val_f1: 0.4349\n",
      "Epoch 3/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.7637 - accuracy: 0.9375 - f1: 0.5046 - val_loss: 1.8404 - val_accuracy: 0.8663 - val_f1: 0.4459\n",
      "Epoch 4/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.7315 - accuracy: 0.9400 - f1: 0.5009 - val_loss: 1.9946 - val_accuracy: 0.8523 - val_f1: 0.4367\n",
      "Epoch 5/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.7065 - accuracy: 0.9415 - f1: 0.4988 - val_loss: 1.9724 - val_accuracy: 0.8429 - val_f1: 0.4360\n",
      "Epoch 6/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.6917 - accuracy: 0.9422 - f1: 0.4972 - val_loss: 1.9796 - val_accuracy: 0.8479 - val_f1: 0.4331\n",
      "Epoch 7/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.6766 - accuracy: 0.9432 - f1: 0.4966 - val_loss: 1.9119 - val_accuracy: 0.8569 - val_f1: 0.4377\n",
      "Epoch 8/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.6690 - accuracy: 0.9440 - f1: 0.4948 - val_loss: 1.9807 - val_accuracy: 0.8537 - val_f1: 0.4352\n",
      "Epoch 9/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.6584 - accuracy: 0.9446 - f1: 0.4952 - val_loss: 2.0279 - val_accuracy: 0.8508 - val_f1: 0.4401\n",
      "Epoch 10/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.6511 - accuracy: 0.9451 - f1: 0.4946 - val_loss: 2.0765 - val_accuracy: 0.8494 - val_f1: 0.4339\n",
      "Epoch 11/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.6470 - accuracy: 0.9455 - f1: 0.4933 - val_loss: 1.9159 - val_accuracy: 0.8389 - val_f1: 0.4311\n",
      "Epoch 12/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.6396 - accuracy: 0.9464 - f1: 0.4931 - val_loss: 1.8351 - val_accuracy: 0.8543 - val_f1: 0.4508\n",
      "Epoch 13/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.6366 - accuracy: 0.9462 - f1: 0.4925 - val_loss: 1.8706 - val_accuracy: 0.8601 - val_f1: 0.4457\n",
      "Epoch 14/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.6302 - accuracy: 0.9470 - f1: 0.4914 - val_loss: 2.2391 - val_accuracy: 0.8269 - val_f1: 0.4329\n",
      "Epoch 15/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.6246 - accuracy: 0.9474 - f1: 0.4915 - val_loss: 1.8445 - val_accuracy: 0.8633 - val_f1: 0.4464\n",
      "Epoch 16/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.6220 - accuracy: 0.9476 - f1: 0.4916 - val_loss: 1.9303 - val_accuracy: 0.8535 - val_f1: 0.4371\n",
      "Epoch 17/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.6162 - accuracy: 0.9479 - f1: 0.4908 - val_loss: 1.9658 - val_accuracy: 0.8411 - val_f1: 0.4338\n",
      "Epoch 18/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.6128 - accuracy: 0.9484 - f1: 0.4913 - val_loss: 1.8151 - val_accuracy: 0.8505 - val_f1: 0.4435\n",
      "Epoch 19/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.6099 - accuracy: 0.9478 - f1: 0.4909 - val_loss: 1.9282 - val_accuracy: 0.8513 - val_f1: 0.4396\n",
      "Epoch 20/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.6070 - accuracy: 0.9484 - f1: 0.4910 - val_loss: 1.8195 - val_accuracy: 0.8630 - val_f1: 0.4390\n",
      "Epoch 21/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.6064 - accuracy: 0.9487 - f1: 0.4909 - val_loss: 1.8436 - val_accuracy: 0.8565 - val_f1: 0.4367\n",
      "Epoch 22/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.6017 - accuracy: 0.9488 - f1: 0.4903 - val_loss: 1.9387 - val_accuracy: 0.8519 - val_f1: 0.4402\n",
      "Epoch 23/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.6005 - accuracy: 0.9491 - f1: 0.4900 - val_loss: 1.8910 - val_accuracy: 0.8507 - val_f1: 0.4310\n",
      "Epoch 24/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5945 - accuracy: 0.9493 - f1: 0.4905 - val_loss: 1.8927 - val_accuracy: 0.8601 - val_f1: 0.4387\n",
      "Epoch 25/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5920 - accuracy: 0.9497 - f1: 0.4893 - val_loss: 1.8638 - val_accuracy: 0.8498 - val_f1: 0.4349\n",
      "Epoch 26/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5890 - accuracy: 0.9498 - f1: 0.4895 - val_loss: 1.8791 - val_accuracy: 0.8534 - val_f1: 0.4367\n",
      "Epoch 27/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5869 - accuracy: 0.9502 - f1: 0.4889 - val_loss: 1.9100 - val_accuracy: 0.8410 - val_f1: 0.4338\n",
      "Epoch 28/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5852 - accuracy: 0.9498 - f1: 0.4891 - val_loss: 1.9157 - val_accuracy: 0.8568 - val_f1: 0.4373\n",
      "Epoch 29/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5842 - accuracy: 0.9498 - f1: 0.4889 - val_loss: 1.7714 - val_accuracy: 0.8573 - val_f1: 0.4376\n",
      "Epoch 30/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5824 - accuracy: 0.9505 - f1: 0.4884 - val_loss: 1.9774 - val_accuracy: 0.8582 - val_f1: 0.4355\n",
      "Epoch 31/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5789 - accuracy: 0.9503 - f1: 0.4880 - val_loss: 1.8746 - val_accuracy: 0.8514 - val_f1: 0.4379\n",
      "Epoch 32/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5777 - accuracy: 0.9503 - f1: 0.4881 - val_loss: 1.7785 - val_accuracy: 0.8591 - val_f1: 0.4361\n",
      "Epoch 33/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5769 - accuracy: 0.9508 - f1: 0.4884 - val_loss: 1.8861 - val_accuracy: 0.8657 - val_f1: 0.4370\n",
      "Epoch 34/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5748 - accuracy: 0.9508 - f1: 0.4879 - val_loss: 1.8481 - val_accuracy: 0.8483 - val_f1: 0.4390\n",
      "Epoch 35/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5761 - accuracy: 0.9509 - f1: 0.4878 - val_loss: 1.9484 - val_accuracy: 0.8484 - val_f1: 0.4368\n",
      "Epoch 36/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5739 - accuracy: 0.9508 - f1: 0.4880 - val_loss: 1.8395 - val_accuracy: 0.8587 - val_f1: 0.4427\n",
      "Epoch 37/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5733 - accuracy: 0.9509 - f1: 0.4879 - val_loss: 1.8568 - val_accuracy: 0.8502 - val_f1: 0.4339\n",
      "Epoch 38/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5708 - accuracy: 0.9512 - f1: 0.4877 - val_loss: 1.8177 - val_accuracy: 0.8553 - val_f1: 0.4391\n",
      "Epoch 39/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5697 - accuracy: 0.9513 - f1: 0.4877 - val_loss: 1.7672 - val_accuracy: 0.8641 - val_f1: 0.4413\n",
      "Epoch 40/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5684 - accuracy: 0.9510 - f1: 0.4876 - val_loss: 1.9110 - val_accuracy: 0.8596 - val_f1: 0.4321\n",
      "Epoch 41/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5661 - accuracy: 0.9516 - f1: 0.4873 - val_loss: 1.8040 - val_accuracy: 0.8628 - val_f1: 0.4402\n",
      "Epoch 42/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5644 - accuracy: 0.9515 - f1: 0.4872 - val_loss: 1.7987 - val_accuracy: 0.8600 - val_f1: 0.4363\n",
      "Epoch 43/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5665 - accuracy: 0.9516 - f1: 0.4867 - val_loss: 1.8207 - val_accuracy: 0.8646 - val_f1: 0.4368\n",
      "Epoch 44/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5605 - accuracy: 0.9520 - f1: 0.4869 - val_loss: 1.8632 - val_accuracy: 0.8655 - val_f1: 0.4380\n",
      "Epoch 45/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5616 - accuracy: 0.9521 - f1: 0.4869 - val_loss: 1.8776 - val_accuracy: 0.8574 - val_f1: 0.4372\n",
      "Epoch 46/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5607 - accuracy: 0.9521 - f1: 0.4869 - val_loss: 1.9100 - val_accuracy: 0.8549 - val_f1: 0.4393\n",
      "Epoch 47/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5615 - accuracy: 0.9518 - f1: 0.4868 - val_loss: 1.8927 - val_accuracy: 0.8465 - val_f1: 0.4370\n",
      "Epoch 48/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5617 - accuracy: 0.9519 - f1: 0.4866 - val_loss: 1.7689 - val_accuracy: 0.8644 - val_f1: 0.4386\n",
      "Epoch 49/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5580 - accuracy: 0.9519 - f1: 0.4863 - val_loss: 1.8681 - val_accuracy: 0.8531 - val_f1: 0.4452\n",
      "Epoch 50/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5583 - accuracy: 0.9520 - f1: 0.4861 - val_loss: 1.7722 - val_accuracy: 0.8511 - val_f1: 0.4410\n",
      "Epoch 51/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5570 - accuracy: 0.9517 - f1: 0.4862 - val_loss: 1.8670 - val_accuracy: 0.8536 - val_f1: 0.4362\n",
      "Epoch 52/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5569 - accuracy: 0.9522 - f1: 0.4856 - val_loss: 1.9166 - val_accuracy: 0.8646 - val_f1: 0.4389\n",
      "Epoch 53/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5547 - accuracy: 0.9522 - f1: 0.4858 - val_loss: 1.8481 - val_accuracy: 0.8611 - val_f1: 0.4413\n",
      "Epoch 54/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5569 - accuracy: 0.9520 - f1: 0.4858 - val_loss: 1.8555 - val_accuracy: 0.8491 - val_f1: 0.4386\n",
      "Epoch 55/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5569 - accuracy: 0.9520 - f1: 0.4864 - val_loss: 1.7911 - val_accuracy: 0.8516 - val_f1: 0.4327\n",
      "Epoch 56/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5505 - accuracy: 0.9525 - f1: 0.4858 - val_loss: 1.8460 - val_accuracy: 0.8636 - val_f1: 0.4415\n",
      "Epoch 57/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5528 - accuracy: 0.9523 - f1: 0.4856 - val_loss: 1.7797 - val_accuracy: 0.8626 - val_f1: 0.4412\n",
      "Epoch 58/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5546 - accuracy: 0.9522 - f1: 0.4855 - val_loss: 1.7838 - val_accuracy: 0.8629 - val_f1: 0.4369\n",
      "Epoch 59/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5506 - accuracy: 0.9526 - f1: 0.4856 - val_loss: 2.0205 - val_accuracy: 0.8624 - val_f1: 0.4387\n",
      "Epoch 60/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5507 - accuracy: 0.9525 - f1: 0.4855 - val_loss: 1.8464 - val_accuracy: 0.8517 - val_f1: 0.4345\n",
      "Epoch 61/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5488 - accuracy: 0.9526 - f1: 0.4853 - val_loss: 1.7703 - val_accuracy: 0.8576 - val_f1: 0.4367\n",
      "Epoch 62/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5498 - accuracy: 0.9527 - f1: 0.4855 - val_loss: 1.7429 - val_accuracy: 0.8536 - val_f1: 0.4406\n",
      "Epoch 63/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5478 - accuracy: 0.9526 - f1: 0.4855 - val_loss: 1.8844 - val_accuracy: 0.8689 - val_f1: 0.4467\n",
      "Epoch 64/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5490 - accuracy: 0.9527 - f1: 0.4855 - val_loss: 1.8128 - val_accuracy: 0.8512 - val_f1: 0.4409\n",
      "Epoch 65/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5474 - accuracy: 0.9528 - f1: 0.4856 - val_loss: 1.8209 - val_accuracy: 0.8721 - val_f1: 0.4429\n",
      "Epoch 66/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5477 - accuracy: 0.9525 - f1: 0.4853 - val_loss: 1.8172 - val_accuracy: 0.8501 - val_f1: 0.4401\n",
      "Epoch 67/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5481 - accuracy: 0.9528 - f1: 0.4854 - val_loss: 1.7930 - val_accuracy: 0.8553 - val_f1: 0.4400\n",
      "Epoch 68/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5440 - accuracy: 0.9530 - f1: 0.4851 - val_loss: 1.9310 - val_accuracy: 0.8569 - val_f1: 0.4360\n",
      "Epoch 69/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5460 - accuracy: 0.9531 - f1: 0.4851 - val_loss: 1.9039 - val_accuracy: 0.8444 - val_f1: 0.4348\n",
      "Epoch 70/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5432 - accuracy: 0.9531 - f1: 0.4852 - val_loss: 1.9801 - val_accuracy: 0.8631 - val_f1: 0.4385\n",
      "Epoch 71/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5421 - accuracy: 0.9534 - f1: 0.4848 - val_loss: 1.8579 - val_accuracy: 0.8595 - val_f1: 0.4425\n",
      "Epoch 72/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5422 - accuracy: 0.9531 - f1: 0.4850 - val_loss: 1.8948 - val_accuracy: 0.8541 - val_f1: 0.4424\n",
      "Epoch 73/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5422 - accuracy: 0.9531 - f1: 0.4856 - val_loss: 1.9310 - val_accuracy: 0.8488 - val_f1: 0.4342\n",
      "Epoch 74/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5451 - accuracy: 0.9530 - f1: 0.4850 - val_loss: 1.9187 - val_accuracy: 0.8515 - val_f1: 0.4390\n",
      "Epoch 75/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5412 - accuracy: 0.9533 - f1: 0.4846 - val_loss: 1.8911 - val_accuracy: 0.8492 - val_f1: 0.4344\n",
      "Epoch 76/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5435 - accuracy: 0.9535 - f1: 0.4853 - val_loss: 1.7494 - val_accuracy: 0.8657 - val_f1: 0.4426\n",
      "Epoch 77/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5402 - accuracy: 0.9534 - f1: 0.4848 - val_loss: 1.8038 - val_accuracy: 0.8685 - val_f1: 0.4439\n",
      "Epoch 78/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5391 - accuracy: 0.9534 - f1: 0.4846 - val_loss: 1.9090 - val_accuracy: 0.8574 - val_f1: 0.4348\n",
      "Epoch 79/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5416 - accuracy: 0.9533 - f1: 0.4848 - val_loss: 1.7946 - val_accuracy: 0.8622 - val_f1: 0.4451\n",
      "Epoch 80/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5395 - accuracy: 0.9530 - f1: 0.4853 - val_loss: 1.9103 - val_accuracy: 0.8581 - val_f1: 0.4368\n",
      "Epoch 81/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5360 - accuracy: 0.9536 - f1: 0.4846 - val_loss: 2.0024 - val_accuracy: 0.8550 - val_f1: 0.4365\n",
      "Epoch 82/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5368 - accuracy: 0.9534 - f1: 0.4851 - val_loss: 1.8333 - val_accuracy: 0.8562 - val_f1: 0.4359\n",
      "Epoch 83/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5376 - accuracy: 0.9535 - f1: 0.4845 - val_loss: 1.9018 - val_accuracy: 0.8570 - val_f1: 0.4351\n",
      "Epoch 84/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5399 - accuracy: 0.9535 - f1: 0.4849 - val_loss: 1.9783 - val_accuracy: 0.8624 - val_f1: 0.4459\n",
      "Epoch 85/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5342 - accuracy: 0.9540 - f1: 0.4844 - val_loss: 1.7887 - val_accuracy: 0.8609 - val_f1: 0.4412\n",
      "Epoch 86/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5343 - accuracy: 0.9535 - f1: 0.4845 - val_loss: 1.7679 - val_accuracy: 0.8595 - val_f1: 0.4422\n",
      "Epoch 87/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5339 - accuracy: 0.9531 - f1: 0.4852 - val_loss: 1.9655 - val_accuracy: 0.8592 - val_f1: 0.4376\n",
      "Epoch 88/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5335 - accuracy: 0.9537 - f1: 0.4845 - val_loss: 1.9217 - val_accuracy: 0.8537 - val_f1: 0.4360\n",
      "Epoch 89/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5356 - accuracy: 0.9539 - f1: 0.4845 - val_loss: 1.9412 - val_accuracy: 0.8603 - val_f1: 0.4378\n",
      "Epoch 90/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5320 - accuracy: 0.9537 - f1: 0.4845 - val_loss: 1.8168 - val_accuracy: 0.8580 - val_f1: 0.4375\n",
      "Epoch 91/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5328 - accuracy: 0.9535 - f1: 0.4841 - val_loss: 1.8839 - val_accuracy: 0.8473 - val_f1: 0.4385\n",
      "Epoch 92/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5303 - accuracy: 0.9540 - f1: 0.4842 - val_loss: 1.8234 - val_accuracy: 0.8664 - val_f1: 0.4395\n",
      "Epoch 93/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5333 - accuracy: 0.9536 - f1: 0.4843 - val_loss: 1.9030 - val_accuracy: 0.8635 - val_f1: 0.4465\n",
      "Epoch 94/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5311 - accuracy: 0.9539 - f1: 0.4845 - val_loss: 1.8603 - val_accuracy: 0.8603 - val_f1: 0.4356\n",
      "Epoch 95/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5301 - accuracy: 0.9537 - f1: 0.4841 - val_loss: 1.8489 - val_accuracy: 0.8590 - val_f1: 0.4415\n",
      "Epoch 96/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5304 - accuracy: 0.9538 - f1: 0.4842 - val_loss: 1.8876 - val_accuracy: 0.8510 - val_f1: 0.4378\n",
      "Epoch 97/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5315 - accuracy: 0.9535 - f1: 0.4848 - val_loss: 1.9233 - val_accuracy: 0.8594 - val_f1: 0.4377\n",
      "Epoch 98/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5296 - accuracy: 0.9539 - f1: 0.4843 - val_loss: 1.8494 - val_accuracy: 0.8608 - val_f1: 0.4416\n",
      "Epoch 99/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5309 - accuracy: 0.9535 - f1: 0.4845 - val_loss: 1.7648 - val_accuracy: 0.8695 - val_f1: 0.4444\n",
      "Epoch 100/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5271 - accuracy: 0.9541 - f1: 0.4842 - val_loss: 2.0655 - val_accuracy: 0.8459 - val_f1: 0.4349\n",
      "Epoch 101/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5266 - accuracy: 0.9541 - f1: 0.4839 - val_loss: 1.8711 - val_accuracy: 0.8638 - val_f1: 0.4495\n",
      "Epoch 102/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5277 - accuracy: 0.9541 - f1: 0.4842 - val_loss: 1.9090 - val_accuracy: 0.8707 - val_f1: 0.4459\n",
      "Epoch 103/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5260 - accuracy: 0.9544 - f1: 0.4840 - val_loss: 1.8473 - val_accuracy: 0.8529 - val_f1: 0.4433\n",
      "Epoch 104/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5246 - accuracy: 0.9541 - f1: 0.4842 - val_loss: 1.8280 - val_accuracy: 0.8649 - val_f1: 0.4417\n",
      "Epoch 105/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5253 - accuracy: 0.9539 - f1: 0.4838 - val_loss: 1.8750 - val_accuracy: 0.8595 - val_f1: 0.4359\n",
      "Epoch 106/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5221 - accuracy: 0.9546 - f1: 0.4840 - val_loss: 1.7824 - val_accuracy: 0.8642 - val_f1: 0.4419\n",
      "Epoch 107/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5245 - accuracy: 0.9545 - f1: 0.4840 - val_loss: 1.8783 - val_accuracy: 0.8663 - val_f1: 0.4431\n",
      "Epoch 108/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5252 - accuracy: 0.9542 - f1: 0.4839 - val_loss: 1.7682 - val_accuracy: 0.8624 - val_f1: 0.4412\n",
      "Epoch 109/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5223 - accuracy: 0.9544 - f1: 0.4836 - val_loss: 1.7329 - val_accuracy: 0.8722 - val_f1: 0.4469\n",
      "Epoch 110/128\n",
      "781963/781963 [==============================] - 1s 2us/sample - loss: 0.5241 - accuracy: 0.9544 - f1: 0.4842 - val_loss: 1.7926 - val_accuracy: 0.8571 - val_f1: 0.4438\n",
      "Epoch 111/128\n",
      "405504/781963 [==============>...............] - ETA: 0s - loss: 0.5187 - accuracy: 0.9542 - f1: 0.4842"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, epochs=128, batch_size=2048, validation_data=(X_val, Y_val[:, 0]), class_weight={0:1, 1:5.69, 2:16.48, 3:5.93})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.ylim((0, 3.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(test_y,pred_y,class_names,normalize=False):\n",
    "    cm = confusion_matrix(test_y,pred_y)\n",
    "    # classes = class_names[unique_labels(test_y,pred_y)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           xticklabels=class_names,\n",
    "           yticklabels=class_names,\n",
    "           ylabel='True label\\n',\n",
    "           xlabel='\\nPredicted label')\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j,\n",
    "                    i,\n",
    "                    format(cm[i, j], fmt),\n",
    "                    ha=\"center\",\n",
    "                    va=\"center\",\n",
    "                    color=\"red\", fontsize=16)\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Still', 'Walking', 'Run', 'Bike', 'Car', 'Bus', 'Train', 'Subway']\n",
    "predict = model.predict_classes(X_val)\n",
    "plot_confusion_matrix(Y_val[:, 0], predict, class_names, True)\n",
    "plt.grid(False)\n",
    "f1_macro = f1_score(Y_val[:, 0], predict, average='macro')\n",
    "round(f1_macro, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold_positions = [\"Bag\", \"Hips\", \"Torso\", \"Hand\"]\n",
    "for i in range(4):\n",
    "    plot_confusion_matrix(Y_val[Y_val[:, 1]==i][:, 0], predict[Y_val[:, 1]==i], class_names, True)\n",
    "    print(round(f1_score(Y_val[Y_val[:, 1]==i][:, 0], predict[Y_val[:, 1]==i], average='macro'), 3))\n",
    "    plt.title(hold_positions[i], fontsize=24)\n",
    "    plt.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データ数をRunのサンプル数に合わせる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Still = X_train[(Y_train==0)[:, 0]]\n",
    "train_Walking = X_train[(Y_train==1)[:, 0]]\n",
    "train_Run = X_train[(Y_train==2)[:, 0]]\n",
    "train_Bike = X_train[(Y_train==3)[:, 0]]\n",
    "\n",
    "train_Still.shape, train_Walking.shape, train_Run.shape, train_Bike.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Still = train_Still[np.random.choice(train_Still.shape[0], 33699, replace=False)]\n",
    "train_Walking = train_Walking[np.random.choice(train_Walking.shape[0], 33699, replace=False)]\n",
    "train_Bike = train_Bike[np.random.choice(train_Bike.shape[0], 33699, replace=False)]\n",
    "\n",
    "train_Still.shape, train_Walking.shape, train_Bike.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate([train_Still, train_Walking, train_Run, train_Bike], axis=0)\n",
    "Y_train = [0] * 33699 + [1] * 33699 + [2] * 33699 + [3] * 33699\n",
    "Y_train = np.array(Y_train).reshape([-1, 1])\n",
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(X_train.shape[1], 1), kernel_initializer=he_normal()))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(4, activation='softmax'))\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy', f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, Y_train, epochs=64, batch_size=512, validation_data=(X_val, Y_val[:, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.ylim((0, 3.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Still', 'Walking', 'Run', 'Bike', 'Car', 'Bus', 'Train', 'Subway']\n",
    "predict = model.predict_classes(X_val)\n",
    "plot_confusion_matrix(Y_val[:, 0], predict, class_names, True)\n",
    "plt.grid(False)\n",
    "f1_macro = f1_score(Y_val[:, 0], predict, average='macro')\n",
    "round(f1_macro, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold_positions = [\"Bag\", \"Hips\", \"Torso\", \"Hand\"]\n",
    "for i in range(4):\n",
    "    plot_confusion_matrix(Y_val[Y_val[:, 1]==i][:, 0], predict[Y_val[:, 1]==i], class_names, True)\n",
    "    print(round(f1_score(Y_val[Y_val[:, 1]==i][:, 0], predict[Y_val[:, 1]==i], average='macro'), 3))\n",
    "    plt.title(hold_positions[i], fontsize=24)\n",
    "    plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
