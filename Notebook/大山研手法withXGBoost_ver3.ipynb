{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分類フロー検証用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(font='Yu Gothic')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_npy(hold_position):\n",
    "    file_path = \"../Output/train/train_\" + hold_position + \"/train_\" + hold_position\n",
    "    xy_mean = np.load(file_path + \"_glo_laccel_xy_mean.npy\")\n",
    "    xy_var = np.load(file_path + \"_glo_laccel_xy_var.npy\")\n",
    "    z_mean = np.load(file_path + \"_glo_laccel_z_mean.npy\")\n",
    "    z_var = np.load(file_path + \"_glo_laccel_z_var.npy\")\n",
    "    z_skew = np.load(file_path + \"_glo_laccel_z_skew.npy\")\n",
    "    z_kurtosis = np.load(file_path + \"_glo_laccel_z_kurtosis.npy\")\n",
    "    z_lacc_FFT = np.load(file_path + \"_glo_laccel_z_amplitude_frequency_range5Hz.npy\")\n",
    "    z_gyro_FFT = np.load(file_path + \"_glo_gyro_z_ver2_amplitude_frequency_range5Hz.npy\")\n",
    "    result = np.concatenate([xy_mean.reshape([-1, 1]), xy_var.reshape([-1, 1]), z_mean.reshape([-1, 1]), z_var.reshape([-1, 1]), z_skew.reshape([-1, 1]), z_kurtosis.reshape([-1, 1]), z_lacc_FFT, z_gyro_FFT], axis=1)\n",
    "    del xy_mean, xy_var, z_mean, z_var, z_skew, z_kurtosis, z_gyro_FFT\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pattern = np.load(\"train_pattern2.npy\")[:, 0]\n",
    "train_pattern = np.concatenate([train_pattern, train_pattern, train_pattern, train_pattern], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(781960, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Label = np.load(\"../Data/センサ別npyファイル/train/train_Bag/train_Bag_Label.npy\")[:, 0].reshape([-1, 1])\n",
    "train_Label = np.delete(train_Label, 120845, 0)\n",
    "train_Label = np.concatenate([train_Label, train_Label, train_Label, train_Label], axis=0)\n",
    "train_Label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((781960, 50), (114740, 50))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pickle.load(open(\"X_train.binaryfile\", \"rb\"))\n",
    "val_data = pickle.load(open(\"X_val.binaryfile\", \"rb\"))\n",
    "\n",
    "train_data.shape, val_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ユーザごとに分けて標準化するためLabel作る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(781960, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user1_Label = [1] * 195490\n",
    "user1_Label = np.array(user1_Label).reshape([-1, 1])\n",
    "user1_Label = np.concatenate([user1_Label, user1_Label, user1_Label, user1_Label])\n",
    "user1_Label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(781960, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Label = np.concatenate([train_Label, user1_Label], axis=1)\n",
    "train_Label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = train_Label\n",
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3., 4., 5., 6., 7., 8.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_Label[:, 0][train_pattern == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Label[:, 0][train_Label[:, 0] == 1] = 0\n",
    "train_Label[:, 0][train_Label[:, 0] >= 5] = 0\n",
    "train_Label[:, 0][train_Label[:, 0] == 2] = 1\n",
    "train_Label[:, 0][train_Label[:, 0] == 3] = 2\n",
    "train_Label[:, 0][train_Label[:, 0] == 4] = 3\n",
    "\n",
    "np.unique(train_Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Bag = np.delete(load_npy(\"Bag\"), 120845, 0)\n",
    "train_Hips = np.delete(load_npy(\"Hips\"), 120845, 0)\n",
    "train_Torso = np.delete(load_npy(\"Torso\"), 120845, 0)\n",
    "train_Hand = np.delete(load_npy(\"Hand\"), 120845, 0)\n",
    "\n",
    "train_Bag.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_npy(hold_position):\n",
    "    file_path = \"../Output/validation/validation_\" + hold_position + \"/validation_\" + hold_position\n",
    "    xy_mean = np.load(file_path + \"_glo_laccel_xy_mean.npy\")\n",
    "    xy_var = np.load(file_path + \"_glo_laccel_xy_var.npy\")\n",
    "    z_mean = np.load(file_path + \"_glo_laccel_z_mean.npy\")\n",
    "    z_var = np.load(file_path + \"_glo_laccel_z_var.npy\")\n",
    "    z_skew = np.load(file_path + \"_glo_laccel_z_skew.npy\")\n",
    "    z_kurtosis = np.load(file_path + \"_glo_laccel_z_kurtosis.npy\")\n",
    "    z_lacc_FFT = np.load(file_path + \"_glo_laccel_z_amplitude_frequency_range5Hz.npy\")\n",
    "    z_gyro_FFT = np.load(file_path + \"_glo_gyro_z_ver2_amplitude_frequency_range5Hz.npy\")\n",
    "    result = np.concatenate([xy_mean.reshape([-1, 1]), xy_var.reshape([-1, 1]), z_mean.reshape([-1, 1]), z_var.reshape([-1, 1]), z_skew.reshape([-1, 1]), z_kurtosis.reshape([-1, 1]), z_lacc_FFT, z_gyro_FFT], axis=1)\n",
    "    del xy_mean, xy_var, z_mean, z_var, z_skew, z_kurtosis, z_gyro_FFT\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114740,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_pattern = np.load(\"validation_pattern2.npy\")[:, 0]\n",
    "validation_pattern = np.concatenate([validation_pattern, validation_pattern, validation_pattern, validation_pattern], axis=0)\n",
    "validation_pattern.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114740, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_Label = np.load(\"../Data/センサ別npyファイル/validation/validation_Bag/validation_Bag_Label.npy\")[:, 0].reshape([-1, 1])\n",
    "validation_Label = np.concatenate([validation_Label, validation_Label, validation_Label, validation_Label], axis=0)\n",
    "validation_Label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ユーザごとに分けて標準化したいのでラベルを用意する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114740, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user23_Label = [2] * 14813 + [3] * 13872\n",
    "user23_Label = np.array(user23_Label).reshape([-1, 1])\n",
    "user23_Label = np.concatenate([user23_Label, user23_Label, user23_Label, user23_Label], axis=0)\n",
    "user23_Label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114740, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_Label = np.concatenate([validation_Label, user23_Label], axis=1)\n",
    "validation_Label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_Label[:, 0][validation_Label[:, 0] == 1] = 0\n",
    "validation_Label[:, 0][validation_Label[:, 0] >= 5] = 0\n",
    "validation_Label[:, 0][validation_Label[:, 0] == 2] = 1\n",
    "validation_Label[:, 0][validation_Label[:, 0] == 3] = 2\n",
    "validation_Label[:, 0][validation_Label[:, 0] == 4] = 3\n",
    "\n",
    "np.unique(validation_Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_Bag = load_npy(\"Bag\")\n",
    "validation_Hips = load_npy(\"Hips\")\n",
    "validation_Torso = load_npy(\"Torso\")\n",
    "validation_Hand = load_npy(\"Hand\")\n",
    "\n",
    "validation_Bag.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(449076, 50)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.concatenate([train_data[train_pattern==1], val_data[validation_pattern==1]])\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate([train_Bag[train_pattern==1], train_Hips[train_pattern==1], train_Torso[train_pattern==1], train_Hand[train_pattern==1],\n",
    "                         validation_Bag[validation_pattern==1], validation_Hips[validation_pattern==1], validation_Torso[validation_pattern==1], validation_Hand[validation_pattern==1]])\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(449076, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train = np.concatenate([train_Label[train_pattern==1], validation_Label[validation_pattern==1]])\n",
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3., 4., 5., 6., 7., 8.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y_train[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-9.27331401e-16, -1.02186207e-16, -5.85213654e-16,  2.20724479e-16,\n",
       "       -9.06392617e-17, -3.77288841e-16, -1.23364511e-16,  2.62934805e+00,\n",
       "       -8.56225433e-16,  8.10098829e+00,  6.10386534e-16,  1.21863323e+01,\n",
       "        5.92319214e-16,  1.72120456e+01,  1.24783536e-15,  2.22008515e+01,\n",
       "       -3.63878841e-16,  2.73768566e+01, -5.36248895e-16,  3.25875781e+01,\n",
       "        2.30325631e-16,  3.79759602e+01, -2.42116249e-16,  4.36479595e+01,\n",
       "       -3.23318665e-16,  4.95473221e+01, -8.97447978e-16,  5.58269001e+01,\n",
       "       -1.04271265e-15,  2.19477109e+00,  1.58263047e-15,  7.54379457e+00,\n",
       "       -3.84146204e-16,  1.20144483e+01,  1.74098129e-15,  1.70546322e+01,\n",
       "        4.18769435e-16,  2.20744158e+01,  2.36942729e-16,  2.73371201e+01,\n",
       "        6.60540958e-16,  3.26894018e+01,  6.86609391e-16,  3.82487007e+01,\n",
       "        7.28765523e-16,  4.37840028e+01,  5.00389057e-17,  4.95736859e+01,\n",
       "        5.04611315e-16,  5.58638623e+01])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.73396538e-02, -3.93006191e-02,  3.40218168e-02, -3.62807713e-02,\n",
       "        8.60189271e-03, -1.63133514e-02, -3.55870344e-02,  2.56147947e+00,\n",
       "       -5.42060617e-02,  8.09626201e+00, -5.34180822e-02,  1.22511172e+01,\n",
       "       -4.47233509e-02,  1.72800795e+01, -4.31124029e-02,  2.21116546e+01,\n",
       "       -5.43906636e-02,  2.72649223e+01, -6.09157422e-02,  3.24872762e+01,\n",
       "       -6.53557271e-02,  3.78033004e+01, -7.31911975e-02,  4.34845661e+01,\n",
       "       -7.18021914e-02,  4.95578390e+01, -7.27416623e-02,  5.60037446e+01,\n",
       "       -2.79353512e-02,  2.16131761e+00, -5.33933292e-02,  7.44163510e+00,\n",
       "       -6.13305334e-02,  1.19924296e+01, -5.84644072e-02,  1.71057696e+01,\n",
       "       -5.79407134e-02,  2.19747756e+01, -5.77092259e-02,  2.71491826e+01,\n",
       "       -5.01284927e-02,  3.24688344e+01, -3.87874131e-02,  3.79117853e+01,\n",
       "       -3.25303972e-02,  4.34838456e+01, -2.72344385e-02,  4.95879160e+01,\n",
       "       -3.20242253e-02,  5.61678868e+01])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[Y_train[:, 1] == 1].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 標準化\n",
    "user1_std = StandardScaler()\n",
    "user2_std = StandardScaler()\n",
    "user3_std = StandardScaler()\n",
    "\n",
    "X_train[Y_train[:, 1] == 1][:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] = user1_std.fit_transform(X_train[Y_train[:, 1] == 1][:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]])\n",
    "X_train[Y_train[:, 1] == 2][:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] = user2_std.fit_transform(X_train[Y_train[:, 1] == 2][:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]])\n",
    "X_train[Y_train[:, 1] == 3][:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] = user3_std.fit_transform(X_train[Y_train[:, 1] == 3][:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Bag[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] = user1_std.transform(train_Bag[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]])\n",
    "train_Hips[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] = user1_std.transform(train_Hips[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]])\n",
    "train_Torso[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] = user1_std.transform(train_Torso[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]])\n",
    "train_Hand[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] = user1_std.transform(train_Hand[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]])\n",
    "\n",
    "validation_Bag[validation_Label[:, 1] == 2][:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] = user2_std.transform(validation_Bag[validation_Label[:, 1] == 2][:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]])\n",
    "validation_Bag[validation_Label[:, 1] == 3][:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] = user3_std.transform(validation_Bag[validation_Label[:, 1] == 3][:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]])\n",
    "\n",
    "validation_Hips[validation_Label[:, 1] == 2][:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] = user2_std.transform(validation_Hips[validation_Label[:, 1] == 2][:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]])\n",
    "validation_Hips[validation_Label[:, 1] == 3][:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] = user3_std.transform(validation_Hips[validation_Label[:, 1] == 3][:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]])\n",
    "\n",
    "validation_Torso[validation_Label[:, 1] == 2][:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] = user2_std.transform(validation_Torso[validation_Label[:, 1] == 2][:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]])\n",
    "validation_Torso[validation_Label[:, 1] == 3][:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] = user3_std.transform(validation_Torso[validation_Label[:, 1] == 3][:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]])\n",
    "\n",
    "validation_Hand[validation_Label[:, 1] == 2][:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] = user2_std.transform(validation_Hand[validation_Label[:, 1] == 2][:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]])\n",
    "validation_Hand[validation_Label[:, 1] == 3][:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] = user3_std.transform(validation_Hand[validation_Label[:, 1] == 3][:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]])\n",
    "\n",
    "train_Hand[:, 1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "user1_mean = pickle.load(open(\"X_train_mean.binaryfile\", \"rb\"))\n",
    "user1_std = pickle.load(open(\"X_train_std.binaryfile\", \"rb\"))\n",
    "user23_mean = pickle.load(open(\"X_val_mean.binaryfile\", \"rb\"))\n",
    "user23_std = pickle.load(open(\"X_val_std.binaryfile\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user1_mean, user1_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[Y_train[:, 1] == 1][:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] = (X_train[Y_train[:, 1] == 1][:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] - user1_mean) / user1_std\n",
    "\n",
    "train_Bag[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] = (train_Bag[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] - user1_mean) / user1_std\n",
    "train_Hips[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] = (train_Hips[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] - user1_mean) / user1_std\n",
    "train_Torso[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] = (train_Torso[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] - user1_mean) / user1_std\n",
    "train_Hand[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] = (train_Hand[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] - user1_mean) / user1_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[Y_train[:, 1] != 1][:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] = (X_train[Y_train[:, 1] != 1][:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] - user23_mean) / user23_std\n",
    "\n",
    "validation_Bag[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] = (validation_Bag[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] - user23_mean) / user23_std\n",
    "validation_Hips[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] = (validation_Hips[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] - user23_mean) / user23_std\n",
    "validation_Torso[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] = (validation_Torso[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] - user23_mean) / user23_std\n",
    "validation_Hand[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] = (validation_Hand[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] - user23_mean) / user23_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 標準化をユーザー1とユーザ23でやる（テストデータはユーザ2なのか3なのかわからないので）\n",
    "\n",
    "std = StandardScaler()\n",
    "\n",
    "std.fit_transform(np.concatenate([train_Bag, train_Hips, train_Torso, train_Hand], axis=0)[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]])\n",
    "\n",
    "X_train[Y_train[:, 1] == 1][:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] = std.transform(X_train[Y_train[:, 1] == 1][:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]])\n",
    "\n",
    "train_Bag[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] = std.transform(train_Bag[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]])\n",
    "train_Hips[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] = std.transform(train_Hips[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]])\n",
    "train_Torso[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] = std.transform(train_Torso[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]])\n",
    "train_Hand[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] = std.transform(train_Hand[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]])\n",
    "\n",
    "std.fit_transform(np.concatenate([validation_Bag, validation_Hips, validation_Torso, validation_Hand], axis=0)[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]])\n",
    "\n",
    "X_train[Y_train[:, 1] != 1][:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] = std.transform(X_train[Y_train[:, 1] != 1][:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]])\n",
    "\n",
    "validation_Bag[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] = std.transform(validation_Bag[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]])\n",
    "validation_Hips[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] = std.transform(validation_Hips[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]])\n",
    "validation_Torso[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] = std.transform(validation_Torso[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]])\n",
    "validation_Hand[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] = std.transform(validation_Hand[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]])\n",
    "\n",
    "train_Hand.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[Y_train[:, 1] == 1].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 標準化\n",
    "# std = StandardScaler()\n",
    "# X_train = std.fit_transform(X_train)\n",
    "# X_val = std.fit_transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 有効桁数減らすとどうなるか\n",
    "X_train = np.round(X_train, 3)\n",
    "X_val = np.round(X_val, 3)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((449076, 50), (449076, 2))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(max_depth=18, min_child_weight=7, learning_rate=0.1, gamma=0.005, sub_sample=0.9, colsample_bytree=0.8, n_estimators=10000,\n",
    "                        n_jobs=-1, tree_method='gpu_hist', gpu_id=0)\n",
    "\n",
    "model.fit(X_train, Y_train[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.8, gamma=0.005, gpu_id=0,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=18,\n",
       "              min_child_weight=7, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10000, n_jobs=-1, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, sub_sample=0.9, subsample=1,\n",
       "              tree_method='gpu_hist', validate_parameters=False,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals_result = {}\n",
    "model = xgb.XGBClassifier(max_depth=18, min_child_weight=7, learning_rate=0.1, gamma=0.005, sub_sample=0.9, colsample_bytree=0.8, n_estimators=10000,\n",
    "                        n_jobs=-1, tree_method='gpu_hist', gpu_id=0)\n",
    "\n",
    "model.fit(X_train[Y_train[:, 1]==1], Y_train[Y_train[:, 1]==1][:, 0], early_stopping_rounds=100, \n",
    "          eval_set=[[X_train[Y_train[:, 1] != 1], Y_train[Y_train[:, 1] != 1][:, 0]]], eval_metric='merror', verbose=False, callbacks=[xgb.callback.record_evaluation(evals_result)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(test_y,pred_y,class_names,normalize=False):\n",
    "    cm = confusion_matrix(test_y,pred_y)\n",
    "    # classes = class_names[unique_labels(test_y,pred_y)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    fig, ax = plt.subplots(figsize=(16, 8))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           xticklabels=class_names,\n",
    "           yticklabels=class_names,\n",
    "           ylabel='True label\\n',\n",
    "           xlabel='\\nPredicted label')\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j,\n",
    "                    i,\n",
    "                    format(cm[i, j], fmt),\n",
    "                    ha=\"center\",\n",
    "                    va=\"center\",\n",
    "                    color=\"red\", fontsize=32)\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Other', 'Walking', 'Run', 'Bike']\n",
    "# class_names = ['Still', 'Walking', 'Run', 'Bike', 'Car', 'Bus', 'Train', 'Subway']\n",
    "predict = model.predict(X_train)\n",
    "plot_confusion_matrix(Y_train[:, 0], predict, class_names, True)\n",
    "plt.grid(False)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "f1_macro = f1_score(Y_train[:, 0], predict, average='macro')\n",
    "round(f1_macro, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Other', 'Walking', 'Run', 'Bike']\n",
    "# class_names = ['Still', 'Walking', 'Run', 'Bike', 'Car', 'Bus', 'Train', 'Subway']\n",
    "predict = model.predict(X_train[Y_train[:, 1] != 1])\n",
    "plot_confusion_matrix(Y_train[Y_train[:, 1] != 1][:, 0], predict, class_names, True)\n",
    "plt.grid(False)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "f1_macro = f1_score(Y_train[Y_train[:, 1] != 1][:, 0], predict, average='macro')\n",
    "round(f1_macro, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, file_name):\n",
    "    x_predict = model.predict(x).reshape([-1, 1])\n",
    "    np.save(file_name, x_predict)\n",
    "    return x_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, file_name):\n",
    "    x_predict = model.predict_proba(x).reshape([-1, 8])\n",
    "    np.save(file_name, x_predict)\n",
    "    return x_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Bag_predict = predict(train_data[train_data.shape[0]//4*0:train_data.shape[0]//4], \"train_Bag_関口分類\")\n",
    "train_Hips_predict = predict(train_data[train_data.shape[0]//4:train_data.shape[0]//4*2], \"train_Hips_関口分類\")\n",
    "train_Torso_predict = predict(train_data[train_data.shape[0]//4*2:train_data.shape[0]//4*3], \"train_Torso_関口分類\")\n",
    "train_Hand_predict = predict(train_data[train_data.shape[0]//4*3:], \"train_Hand_関口分類\")\n",
    "\n",
    "validation_Bag_predict = predict(val_data[val_data.shape[0]//4*0:val_data.shape[0]//4], \"validation_Bag_関口分類\")\n",
    "validation_Hips_predict = predict(val_data[val_data.shape[0]//4:val_data.shape[0]//4*2], \"validation_Hips_関口分類\")\n",
    "validation_Torso_predict = predict(val_data[val_data.shape[0]//4*2:val_data.shape[0]//4*3], \"validation_Torso_関口分類\")\n",
    "validation_Hand_predict = predict(val_data[val_data.shape[0]//4*3:], \"validation_Hand_関口分類\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Bag_predict = predict(train_Bag, \"train_Bag_関口分類\")\n",
    "train_Hips_predict = predict(train_Hips, \"train_Hips_関口分類\")\n",
    "train_Torso_predict = predict(train_Torso, \"train_Torso_関口分類\")\n",
    "train_Hand_predict = predict(train_Hand, \"train_Hand_関口分類\")\n",
    "\n",
    "validation_Bag_predict = predict(validation_Bag, \"validation_Bag_関口分類\")\n",
    "validation_Hips_predict = predict(validation_Hips, \"validation_Hips_関口分類\")\n",
    "validation_Torso_predict = predict(validation_Torso, \"validation_Torso_関口分類\")\n",
    "validation_Hand_predict = predict(validation_Hand, \"validation_Hand_関口分類\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Bag_predict.shape, train_Label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_macro = f1_score(validation_Label[:, 0], validation_Bag_predict, average='macro')\n",
    "f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(Y_train[:, 0]), np.unique(train_Label[:, 0]), np.unique(validation_Label[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(train_Bag_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Other', 'Walking', 'Run', 'Bike']\n",
    "# class_names = ['Still', 'Walking', 'Run', 'Bike', 'Car', 'Bus', 'Train', 'Subway']\n",
    "predict = model.predict(X_train)\n",
    "plot_confusion_matrix(train_Label[:, 0], train_Bag_predict, class_names, True)\n",
    "plt.grid(False)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "f1_macro = f1_score(train_Label[:, 0], train_Bag_predict, average='macro')\n",
    "round(f1_macro, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(12, 24))\n",
    "xgb.plot_importance(model,\n",
    "                    ax=ax,\n",
    "                    importance_type='gain',\n",
    "                    show_values=False)\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_user1 = X_train[Y_train[:, 1] == 1]\n",
    "X_train_user2 = X_train[Y_train[:, 1] == 2]\n",
    "X_train_user3 = X_train[Y_train[:, 1] == 3]\n",
    "Y_train_user1 = Y_train[Y_train[:, 1] == 1]\n",
    "Y_train_user2 = Y_train[Y_train[:, 1] == 2]\n",
    "Y_train_user3 = Y_train[Y_train[:, 1] == 3]\n",
    "\n",
    "X_train_train = np.concatenate([X_train_user1[:X_train_user1.shape[0]//10*7], X_train_user2[:X_train_user2.shape[0]//10*7], X_train_user3[:X_train_user3.shape[0]//10*7]], axis=0)\n",
    "X_train_val = np.concatenate([X_train_user1[X_train_user1.shape[0]//10*7:], X_train_user2[X_train_user2.shape[0]//10*7:], X_train_user3[X_train_user3.shape[0]//10*7:]], axis=0)\n",
    "Y_train_train = np.concatenate([Y_train_user1[:Y_train_user1.shape[0]//10*7], Y_train_user2[:Y_train_user2.shape[0]//10*7], Y_train_user3[:Y_train_user3.shape[0]//10*7]], axis=0)\n",
    "Y_train_val = np.concatenate([Y_train_user1[Y_train_user1.shape[0]//10*7:], Y_train_user2[Y_train_user2.shape[0]//10*7:], Y_train_user3[Y_train_user3.shape[0]//10*7:]], axis=0)\n",
    "\n",
    "X_train_train.shape, Y_train_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_f1_score = 0\n",
    "best_param = {}\n",
    "\n",
    "max_depth = [i for i in range(6, 19, 6)]\n",
    "min_child_weight = [i for i in range(1, 10, 3)]\n",
    "count = 1\n",
    "for i in max_depth:\n",
    "    for j in min_child_weight:\n",
    "        model = xgb.XGBClassifier(max_depth=i, min_child_weight=j, learning_rate=0.1,\n",
    "                                  n_jobs=-1, tree_method='gpu_hist', gpu_id=0)\n",
    "        model.fit(X_train_train, Y_train_train[:, 0])\n",
    "        print(\"{}回終わった\".format(count))\n",
    "        count += 1\n",
    "        predict = model.predict(X_train_val)\n",
    "        f1_macro = f1_score(Y_train_val[:, 0], predict, average='macro')\n",
    "        print({'max_depth': i, 'min_child_weight': j}, f1_macro)\n",
    "        if f1_macro > best_f1_score:\n",
    "            best_f1_score = f1_macro\n",
    "            best_param = {'max_depth': i, 'min_child_weight': j}\n",
    "\n",
    "print(round(best_f1_score, 3))\n",
    "print(best_param)\n",
    "\n",
    "# param = {\n",
    "#     \"max_depth\":[i for i in range(3, 16, 3)], \"min_child_weight\":[i for i in range(6, 13, 2)]\n",
    "#     # \"gamma\":[0.01, 0.05, 0.075, 0.1]\n",
    "#     # \"subsample\":[0.70, 0.75, 0.80, 0.85, 0.90, 0.95, 1.00], \"colsample_bytree\":[0.70, 0.75, 0.80, 0.85, 0.90, 0.95, 1.00]\n",
    "#     # \"n_estimators\":[250, 500, 750], \"learning_rate\":[0.05, 0.1]\n",
    "#     # \"reg_alpha\":[0.1, 0.25, 0.5, 0.75]\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの分布を確認することは重要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = X_test.shape[0]//4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = Y_train[~np.isnan(X_train)[:, 0]].reshape([-1, 1])\n",
    "X_train = X_train[~np.isnan(X_train)[:, 0], :]\n",
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold_positions = ['Bag', 'Hips', 'Torso', 'Hand']\n",
    "train = [train_Bag, train_Hips, train_Torso, train_Hand]\n",
    "test = [validation_Bag, validation_Hips, validation_Torso, validation_Hand]\n",
    "moving_states = ['Still（乗り物も）', 'Walking', 'Run', 'Bike']\n",
    "\n",
    "sensors = [\"世界座標系線形加速度XY平均\", \"世界座標系線形加速度XY分散\", \"世界座標系線形加速度Z平均\", \"世界座標系線形加速度Z分散\", \"世界座標系線形加速度Z歪度\", \"世界座標系線形加速度Z尖度\", \"世界座標系線形加速度Z_FFT_MaxAmplitude\", \"世界座標系線形加速度Z_FFT_MaxAmplitude_Frequency\"]\n",
    "\n",
    "def hist_plot(sensor):\n",
    "    fig = plt.figure(figsize=(24, 16))\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.4, hspace=0.2)\n",
    "    print(sensor)\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            plt.subplot(4, 4, i*4 + (j+1))\n",
    "            try:\n",
    "                sns.distplot(train[i][:, sensor].reshape([-1, 1])[train_Y==j+1], bins=21, label='train_' + hold_positions[i] + \"_\" + moving_states[j])\n",
    "                sns.distplot(test[i][:, sensor].reshape([-1, 1])[test_Y==j+1], bins=21, label='val_' + hold_positions[i] + \"_\" + moving_states[j])\n",
    "            except:\n",
    "                pass\n",
    "            plt.legend()\n",
    "#     fig.suptitle(sensors[sensor], fontsize=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(X_train.shape[1]):\n",
    "    hist_plot(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(24, 16))\n",
    "\n",
    "plt.subplots_adjust(wspace=0.4, hspace=0.2)\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        plt.subplot(4, 4, i*4 + (j+1))\n",
    "        sns.distplot(train[i][:, 3].reshape([-1, 1])[train_Y==j+1], bins=21, label='train_' + hold_positions[i] + \"_\" + moving_states[j])\n",
    "        sns.distplot(test[i][:, 3].reshape([-1, 1])[test_Y==j+1], bins=21, label='val_' + hold_positions[i] + \"_\" + moving_states[j])\n",
    "        plt.xlim(-1, 10000)\n",
    "        plt.ylim(0, 0.003)\n",
    "        plt.legend()\n",
    "fig.suptitle(sensors[3], fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "def hist_plot(sensor):\n",
    "    fig = plt.figure(figsize=(24, 16))\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.4, hspace=0.2)\n",
    "\n",
    "    for i in range(4):\n",
    "        train_std = train[i][np.isnan(train[i]).any(axis=1) == False].reshape([-1, X_train.shape[1]])\n",
    "        train_Y_std = train_Y[np.isnan(train[i]).any(axis=1) == False]\n",
    "        train_std = (train_std - train_std.mean()) / train_std.std()\n",
    "        test_std = (test[i] - test[i].mean()) / test[i].std()\n",
    "#         train_std = StandardScaler().fit_transform(train_std[:, sensor].reshape([-1, 1]))\n",
    "#         test_std = StandardScaler().fit_transform(test[i][:, sensor].reshape([-1, 1]))\n",
    "        print(train_std.mean(), test_std.mean())\n",
    "        print(train_std.var(), test_std.var())\n",
    "        for j in range(4):\n",
    "            plt.subplot(4, 4, i*4 + (j+1))\n",
    "            sns.distplot(train_std[:, sensor].reshape([-1, 1])[train_Y_std==j+1], bins=21, label='train_' + hold_positions[i] + \"_\" + moving_states[j])\n",
    "            sns.distplot(test_std[:, sensor].reshape([-1, 1])[test_Y==j+1], bins=21, label='val_' + hold_positions[i] + \"_\" + moving_states[j])\n",
    "            plt.legend()\n",
    "#     fig.suptitle(sensors[sensor], fontsize=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(zscore(train[0][:, 0], axis=0))\n",
    "np.where(np.isnan(train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(np.isinf(train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# それぞれのスケールで標準化した特徴量をプロット\n",
    "for i in range(X_train.shape[1]):\n",
    "    hist_plot(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# パターン1,3.5は手動でやる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user1_load(hold_position):\n",
    "    file_path = \"../Output/train/train_\" + hold_position + \"/train_\" + hold_position\n",
    "    xy_mean = np.load(file_path + \"_glo_laccel_xy_mean.npy\")\n",
    "    xy_var = np.load(file_path + \"_glo_laccel_xy_var.npy\")\n",
    "    z_mean = np.load(file_path + \"_glo_laccel_z_mean.npy\")\n",
    "    z_var = np.load(file_path + \"_glo_laccel_z_var.npy\")\n",
    "    z_skew = np.load(file_path + \"_glo_laccel_z_skew.npy\")\n",
    "    z_kurtosis = np.load(file_path + \"_glo_laccel_z_kurtosis.npy\")\n",
    "    z_lacc_FFT = np.load(file_path + \"_glo_laccel_z_amplitude_frequency_range5Hz.npy\")\n",
    "    z_gyro_FFT = np.load(file_path + \"_glo_gyro_z_ver2_amplitude_frequency_range5Hz.npy\")\n",
    "    result = np.concatenate([xy_mean.reshape([-1, 1]), xy_var.reshape([-1, 1]), z_mean.reshape([-1, 1]), z_var.reshape([-1, 1]), z_skew.reshape([-1, 1]), z_kurtosis.reshape([-1, 1]), z_lacc_FFT, z_gyro_FFT], axis=1)\n",
    "    del xy_mean, xy_var, z_mean, z_var, z_skew, z_kurtosis, z_gyro_FFT\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user1_Label = np.delete(np.load(\"../Data/センサ別npyファイル/train/train_Bag/train_Bag_Label.npy\")[:, 0].reshape([-1, 1]), 120845, 0)\n",
    "user1_Label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user1_Bag = np.delete(user1_load(\"Bag\"), 120845, 0)\n",
    "user1_Hips = np.delete(user1_load(\"Hips\"), 120845, 0)\n",
    "user1_Torso = np.delete(user1_load(\"Torso\"), 120845, 0)\n",
    "user1_Hand = np.delete(user1_load(\"Hand\"), 120845, 0)\n",
    "\n",
    "user1_Hand.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user2_load(hold_position):\n",
    "    file_path = \"../Output/validation/validation_\" + hold_position + \"/validation_\" + hold_position\n",
    "    xy_mean = np.load(file_path + \"_glo_laccel_xy_mean.npy\")\n",
    "    xy_var = np.load(file_path + \"_glo_laccel_xy_var.npy\")\n",
    "    z_mean = np.load(file_path + \"_glo_laccel_z_mean.npy\")\n",
    "    z_var = np.load(file_path + \"_glo_laccel_z_var.npy\")\n",
    "    z_skew = np.load(file_path + \"_glo_laccel_z_skew.npy\")\n",
    "    z_kurtosis = np.load(file_path + \"_glo_laccel_z_kurtosis.npy\")\n",
    "    z_lacc_FFT = np.load(file_path + \"_glo_laccel_z_amplitude_frequency_range5Hz.npy\")\n",
    "    z_gyro_FFT = np.load(file_path + \"_glo_gyro_z_ver2_amplitude_frequency_range5Hz.npy\")\n",
    "    result = np.concatenate([xy_mean.reshape([-1, 1]), xy_var.reshape([-1, 1]), z_mean.reshape([-1, 1]), z_var.reshape([-1, 1]), z_skew.reshape([-1, 1]), z_kurtosis.reshape([-1, 1]), z_lacc_FFT, z_gyro_FFT], axis=1)\n",
    "    del xy_mean, xy_var, z_mean, z_var, z_skew, z_kurtosis, z_gyro_FFT\n",
    "    return result[:14813]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user2_Label = np.load(\"../Data/センサ別npyファイル/validation/validation_Bag/validation_Bag_Label.npy\")[:14813, 0].reshape([-1, 1])\n",
    "user2_Label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user2_Bag = user2_load(\"Bag\")\n",
    "user2_Hips = user2_load(\"Hips\")\n",
    "user2_Torso = user2_load(\"Torso\")\n",
    "user2_Hand = user2_load(\"Hand\")\n",
    "\n",
    "user2_Hand.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user3_load(hold_position):\n",
    "    file_path = \"../Output/validation/validation_\" + hold_position + \"/validation_\" + hold_position\n",
    "    xy_mean = np.load(file_path + \"_glo_laccel_xy_mean.npy\")\n",
    "    xy_var = np.load(file_path + \"_glo_laccel_xy_var.npy\")\n",
    "    z_mean = np.load(file_path + \"_glo_laccel_z_mean.npy\")\n",
    "    z_var = np.load(file_path + \"_glo_laccel_z_var.npy\")\n",
    "    z_skew = np.load(file_path + \"_glo_laccel_z_skew.npy\")\n",
    "    z_kurtosis = np.load(file_path + \"_glo_laccel_z_kurtosis.npy\")\n",
    "    z_lacc_FFT = np.load(file_path + \"_glo_laccel_z_amplitude_frequency_range5Hz.npy\")\n",
    "    z_gyro_FFT = np.load(file_path + \"_glo_gyro_z_ver2_amplitude_frequency_range5Hz.npy\")\n",
    "    result = np.concatenate([xy_mean.reshape([-1, 1]), xy_var.reshape([-1, 1]), z_mean.reshape([-1, 1]), z_var.reshape([-1, 1]), z_skew.reshape([-1, 1]), z_kurtosis.reshape([-1, 1]), z_lacc_FFT, z_gyro_FFT], axis=1)\n",
    "    del xy_mean, xy_var, z_mean, z_var, z_skew, z_kurtosis, z_gyro_FFT\n",
    "    return result[14813:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user3_Label = np.load(\"../Data/センサ別npyファイル/validation/validation_Bag/validation_Bag_Label.npy\")[14813:, 0].reshape([-1, 1])\n",
    "user3_Label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user3_Bag = user3_load(\"Bag\")\n",
    "user3_Hips = user3_load(\"Hips\")\n",
    "user3_Torso = user3_load(\"Torso\")\n",
    "user3_Hand = user3_load(\"Hand\")\n",
    "\n",
    "user3_Hand.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パターン1\n",
    "X_train = np.concatenate([user1_Bag, user1_Hips, user1_Torso, user1_Hand], axis=0)\n",
    "Y_train = np.concatenate([user1_Label, user1_Label, user1_Label, user1_Label], axis=0)\n",
    "\n",
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = StandardScaler()\n",
    "\n",
    "X_train[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] = std.fit_transform(\n",
    "    X_train[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]])\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(max_depth=18, min_child_weight=7, learning_rate=0.1, \n",
    "                          n_jobs=-1, tree_method='gpu_hist', gpu_id=0,\n",
    "                         gamma=0.1, sub_sample=1.0, colsample_bytree=1.0)\n",
    "# model.fit(X_val_train, Y_val_train[:, 0])\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, file_name):\n",
    "    x_predict = model.predict(x).reshape([-1, 1])\n",
    "    np.save(file_name, x_predict)\n",
    "    return x_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user1_Bag[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] = std.transform(user1_Bag[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]])\n",
    "user1_Hips[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] = std.transform(user1_Hips[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]])\n",
    "user1_Torso[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] = std.transform(user1_Torso[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]])\n",
    "user1_Hand[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]] = std.transform(user1_Hand[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_Bag = np.concatenate([user2_Bag, user3_Bag], axis=0)\n",
    "validation_Hips = np.concatenate([user2_Hips, user3_Hips], axis=0)\n",
    "validation_Torso = np.concatenate([user2_Torso, user3_Torso], axis=0)\n",
    "validation_Hand = np.concatenate([user2_Hand, user3_Hand], axis=0)\n",
    "\n",
    "validation = np.concatenate([validation_Bag, validation_Hips, validation_Torso, validation_Hand], axis=0)\n",
    "std.fit_transform(validation[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]])\n",
    "\n",
    "validation_Bag[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48] = std.transform(\n",
    "    validation_Bag[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]])\n",
    "\n",
    "validation_Bag[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48] = std.transform(\n",
    "    validation_Bag[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]])\n",
    "\n",
    "validation_Bag[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48] = std.transform(\n",
    "    validation_Bag[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]])\n",
    "    \n",
    "validation_Bag[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48] = std.transform(\n",
    "    validation_Bag[:, [0,1,2,3,4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Bag_predict = predict(user1_Bag, \"train_Bag_関口分類\")\n",
    "train_Hips_predict = predict(user1_Hips, \"train_Hips_関口分類\")\n",
    "train_Torso_predict = predict(user1_Torso, \"train_Torso_関口分類\")\n",
    "train_Hand_predict = predict(user_Hand, \"train_Hand_関口分類\")\n",
    "\n",
    "validation_Bag_predict = predict(validation_Bag, \"validation_Bag_関口分類\")\n",
    "validation_Hips_predict = predict(validation_Hips, \"validation_Hips_関口分類\")\n",
    "validation_Torso_predict = predict(validation_Torso, \"validation_Torso_関口分類\")\n",
    "validation_Hand_predict = predict(validation_Hand, \"validation_Hand_関口分類\")\n"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
