{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(font='Yu Gothic')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_lacc_x = np.loadtxt(\"../Data/Raw/validation/Bag/LAcc_x.txt\")\n",
    "val_lacc_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_lacc_x = val_lacc_x.flatten()\n",
    "val_lacc_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(64, 8))\n",
    "plt.plot(val_lacc_x[7000:10000])\n",
    "plt.title(\"Validation_Bag 端末座標系LAcc\")\n",
    "plt.xlabel(\"Point\")\n",
    "plt.ylabel(\"m/s^2\")\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TrainデータのNGラベル除いてnpyファイル化する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(196072, 500)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = np.loadtxt(\"../Data/Raw/train/Hips/Label.txt\")\n",
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 196072/196072 [00:01<00:00, 111572.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "NGindex = []\n",
    "for i in tqdm(range(label.shape[0])):\n",
    "    if np.unique(label[i]).size > 1:\n",
    "        NGindex.append(i)\n",
    "        \n",
    "print(len(NGindex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReturnUnique(x):\n",
    "    return np.delete(x, NGindex, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadtxt(hold_position, sensor, version):\n",
    "    file_path = \"../Data/Raw/train/\" + hold_position + \"/Glo_\" + sensor + \"_\"\n",
    "    x = np.loadtxt(file_path + \"x_ver\" + version + \".txt\")\n",
    "    y = np.loadtxt(file_path + \"y_ver\" + version + \".txt\")\n",
    "    z = np.loadtxt(file_path + \"z_ver\" + version + \".txt\")\n",
    "    x = ReturnUnique(x).reshape([-1, 500, 1])\n",
    "    y = ReturnUnique(y).reshape([-1, 500, 1])\n",
    "    z = ReturnUnique(z).reshape([-1, 500, 1])\n",
    "    result = np.concatenate([x, y, z], axis=2)\n",
    "    np.save(\"train_\" + hold_position + \"_Glo_\" + sensor + \"_ver\" + version, result)\n",
    "#     np.save(\"../Data/センサ別npyファイル/train/train_\" + hold_position + \"/train_\" + hold_position + \"_Glo_\" + sensor + \"_ver\" + version, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hold_positions = [\"Bag\", \"Hips\", \"Torso\", \"Hand\"]\n",
    "hold_positions = [\"Hips\"]\n",
    "sensors = [\"Mag\"]\n",
    "versions = [\"2\"]\n",
    "for sensor in tqdm(sensors):\n",
    "    for version in tqdm(versions):\n",
    "        for hold_position in tqdm(hold_positions):\n",
    "            loadtxt(hold_position, sensor, version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load(\"../Data/センサ別npyファイル/train/train_Bag/train_Bag_Glo_LAcc_ver2.npy\")\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validationデータもやる\n",
    "## なんとvalidationデータも5秒間同じラベルが続かないセグメントが100程度あった！！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28789, 500)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = np.loadtxt(\"../Data/Raw/validation/Hips/Label.txt\")\n",
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 28789/28789 [00:00<00:00, 104290.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "NGindex = []\n",
    "for i in tqdm(range(label.shape[0])):\n",
    "    if np.unique(label[i]).size > 1:\n",
    "        NGindex.append(i)\n",
    "        \n",
    "print(len(NGindex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReturnUnique(x):\n",
    "    return np.delete(x, NGindex, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadtxt(hold_position, sensor, version):\n",
    "    file_path = \"../Data/Raw/validation/\" + hold_position + \"/Glo_\" + sensor + \"_\"\n",
    "    x = np.loadtxt(file_path + \"x_ver\" + version + \".txt\")\n",
    "    y = np.loadtxt(file_path + \"y_ver\" + version + \".txt\")\n",
    "    z = np.loadtxt(file_path + \"z_ver\" + version + \".txt\")\n",
    "    x = ReturnUnique(x).reshape([-1, 500, 1])\n",
    "    y = ReturnUnique(y).reshape([-1, 500, 1])\n",
    "    z = ReturnUnique(z).reshape([-1, 500, 1])\n",
    "    result = np.concatenate([x, y, z], axis=2)\n",
    "    np.save(\"validation_\" + hold_position + \"_Glo_\" + sensor + \"_ver3\", result)\n",
    "#     np.save(\"../Data/センサ別npyファイル/validation/validation_\" + hold_position + \"/validation_\" + hold_position + \"_Glo_\" + sensor + \"_ver\" + version, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:37<00:00, 37.37s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:37<00:00, 37.37s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:37<00:00, 37.37s/it]\u001b[A\u001b[A\u001b[A\n"
     ]
    }
   ],
   "source": [
    "# hold_positions = [\"Bag\", \"Hips\", \"Torso\", \"Hand\"]\n",
    "hold_positions = [\"Hips\"]\n",
    "sensors = [\"Mag\"]\n",
    "versions = [\"3\"]\n",
    "for sensor in tqdm(sensors):\n",
    "    for version in tqdm(versions):\n",
    "        for hold_position in tqdm(hold_positions):\n",
    "            loadtxt(hold_position, sensor, version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadtxt(hold_position):\n",
    "    file_path = \"../Data/Raw/validation/\" + hold_position + \"/Glo_LAcc_\"\n",
    "    x = np.loadtxt(file_path + \"x_ver3.txt\")\n",
    "    y = np.loadtxt(file_path + \"y_ver3.txt\")\n",
    "    z = np.loadtxt(file_path + \"z_ver3.txt\")\n",
    "    x = ReturnUnique(x).reshape([-1, 500, 1])\n",
    "    y = ReturnUnique(y).reshape([-1, 500, 1])\n",
    "    z = ReturnUnique(z).reshape([-1, 500, 1])\n",
    "    result = np.concatenate([x, y, z], axis=2)\n",
    "    np.save(\"../Data/センサ別npyファイル/validation/validation_\" + hold_position + \"/validation_\" + hold_position + \"_Glo_LAcc_ver3\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold_positions = [\"Bag\", \"Hips\", \"Torso\", \"Hand\"]\n",
    "\n",
    "for hold_position in tqdm(hold_positions):\n",
    "    loadtxt(hold_position)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testデータも！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadtxt(sensor, version):\n",
    "    file_path = \"../Data/Raw/test/Glo_\" + sensor + \"_\"\n",
    "    x = np.loadtxt(file_path + \"x_ver\" + version + \".txt\").reshape([-1, 500, 1])\n",
    "    y = np.loadtxt(file_path + \"y_ver\" + version + \".txt\").reshape([-1, 500, 1])\n",
    "    z = np.loadtxt(file_path + \"z_ver\" + version + \".txt\").reshape([-1, 500, 1])\n",
    "    result = np.concatenate([x, y, z], axis=2)\n",
    "    np.save(\"../Data/センサ別npyファイル/test/test_Glo_\" + sensor + \"_ver\" + version, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors = [\"Mag\"]\n",
    "versions = [\"2\", \"3\"]\n",
    "\n",
    "for sensor in tqdm(sensors):\n",
    "    for version in versions:\n",
    "        loadtxt(sensor, version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadtxt():\n",
    "    file_path = \"../Data/Raw/test/Glo_Mag_\"\n",
    "    x = np.loadtxt(file_path + \"x_ver3.txt\").reshape([-1, 500, 1])\n",
    "    y = np.loadtxt(file_path + \"y_ver3.txt\").reshape([-1, 500, 1])\n",
    "    z = np.loadtxt(file_path + \"z_ver3.txt\").reshape([-1, 500, 1])\n",
    "    result = np.concatenate([x, y, z], axis=2)\n",
    "    np.save(\"../Data/センサ別npyファイル/test/test_Glo_Mag_ver3\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadtxt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.load(\"../Data/センサ別npyファイル/test/test_Glo_LAcc_ver2.npy\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
