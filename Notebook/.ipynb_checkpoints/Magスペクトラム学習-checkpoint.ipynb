{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import scipy\n",
    "from scipy import signal\n",
    "from numpy.fft import fft\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.initializers import he_normal\n",
    "from tensorflow.python.keras.utils.vis_utils import plot_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(font='Yu Gothic')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(test_y,pred_y,class_names,normalize=False, figsize=(16, 8)):\n",
    "    cm = confusion_matrix(test_y,pred_y)\n",
    "    # classes = class_names[unique_labels(test_y,pred_y)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           xticklabels=class_names,\n",
    "           yticklabels=class_names,\n",
    "           ylabel='True label\\n',\n",
    "           xlabel='\\nPredicted label')\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j,\n",
    "                    i,\n",
    "                    format(cm[i, j], fmt),\n",
    "                    ha=\"center\",\n",
    "                    va=\"center\",\n",
    "                    color=\"red\", fontsize=16)\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Label = np.delete(np.load(\"../Data/センサ別npyファイル/train/train_Bag/train_Bag_LAbel.npy\")[:, 0], 120845, 0).reshape([-1, 1])\n",
    "Y_train = train_Label\n",
    "train_Label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_npy(hold_position):\n",
    "    mag = np.delete(np.load(\"../Output/train/train_\" + hold_position + \"/train_\" + hold_position + \"_glo_mag_norm_spectram.npy\"), 120845, 0)[:, :40, :]\n",
    "    mag = mag[(Y_train.reshape([-1]) == 1) | (Y_train.reshape([-1]) >= 5)]\n",
    "    return mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Bag = load_npy(\"Bag\")\n",
    "train_Hips = load_npy(\"Hips\")\n",
    "train_Torso = load_npy(\"Torso\")\n",
    "train_Hand = load_npy(\"Hand\")\n",
    "\n",
    "train_Hand.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = np.concatenate([train_Bag, train_Hips, train_Torso, train_Hand], axis=0)\n",
    "X_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = X_train1.reshape([-1, X_train1.shape[1], X_train1.shape[2], 1])\n",
    "\n",
    "X_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_npy(hold_position):\n",
    "    lacc = np.delete(np.load(\"../Output/train/train_\" + hold_position + \"/train_\" + hold_position + \"_glo_lacc_norm_spectram.npy\"), 120845, 0)[:, :64, :]\n",
    "    lacc = lacc[(Y_train.reshape([-1]) == 1) | (Y_train.reshape([-1]) >= 5)]\n",
    "    return lacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Bag = load_npy(\"Bag\")\n",
    "train_Hips = load_npy(\"Hips\")\n",
    "train_Torso = load_npy(\"Torso\")\n",
    "train_Hand = load_npy(\"Hand\")\n",
    "\n",
    "train_Hand.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = np.concatenate([train_Bag, train_Hips, train_Torso, train_Hand], axis=0)\n",
    "X_train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = X_train2.reshape([-1, X_train2.shape[1], X_train2.shape[2], 1])\n",
    "\n",
    "X_train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_npy(hold_position):\n",
    "    gyr = np.delete(np.load(\"../Output/train/train_\" + hold_position + \"/train_\" + hold_position + \"_glo_gyr_norm_spectram.npy\"), 120845, 0)[:, :64, :]\n",
    "    gyr = gyr[(Y_train.reshape([-1]) == 1) | (Y_train.reshape([-1]) >= 5)]\n",
    "    return gyr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Bag = load_npy(\"Bag\")\n",
    "train_Hips = load_npy(\"Hips\")\n",
    "train_Torso = load_npy(\"Torso\")\n",
    "train_Hand = load_npy(\"Hand\")\n",
    "\n",
    "train_Hand.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train3 = np.concatenate([train_Bag, train_Hips, train_Torso, train_Hand], axis=0)\n",
    "X_train3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train3 = X_train3.reshape([-1, X_train3.shape[1], X_train3.shape[2], 1])\n",
    "\n",
    "X_train3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_Bag, train_Hips, train_Torso, train_Hand, train_Label, mag, gyr, lacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.concatenate([Y_train, Y_train, Y_train, Y_train], axis=0)\n",
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = Y_train[(Y_train.reshape([-1]) == 1) | (Y_train.reshape([-1]) >= 5)]\n",
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train[Y_train.reshape([-1]) == 1] = 0\n",
    "\n",
    "Y_train[Y_train.reshape([-1]) >= 5] = Y_train[Y_train.reshape([-1]) >= 5] - 4\n",
    "\n",
    "np.unique(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1, x_test1, y_train, y_test = train_test_split(X_train1, Y_train, test_size=0.3, shuffle=False)\n",
    "x_train2, x_test2 = train_test_split(X_train2, test_size=0.3, shuffle=False)\n",
    "x_train3, x_test3 = train_test_split(X_train3, test_size=0.3, shuffle=False)\n",
    "\n",
    "x_train1.shape, x_test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train1, X_train2, X_train3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuildModel(input_shape):\n",
    "    input1 = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='valid', activation='relu', kernel_initializer=he_normal())(input1)\n",
    "    x = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(16, activation='relu')(x)\n",
    "    x = models.Model(inputs=input1, outputs=x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x1 = BuildModel(x_train1[0].shape)\n",
    "x2 = BuildModel(x_train2[0].shape)\n",
    "x3 = BuildModel(x_train3[0].shape)\n",
    "\n",
    "combined = layers.concatenate([x1.output, x2.output, x3.output])\n",
    "\n",
    "z = layers.Dense(64, activation='relu')(combined)\n",
    "z = layers.Dense(16, activation='relu')(z)\n",
    "z = layers.Dense(5, activation='softmax')(z)\n",
    "\n",
    "model = models.Model(inputs=[x1.input, x2.input, x3.input], outputs=z)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True, show_layer_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cp_cb = tf.keras.callbacks.ModelCheckpoint(filepath=\"../Output/CheckPoint/mag_norm/model_{epoch:02d}-{loss:.2f}-{accuracy:.2f}-{val_loss:.2f}-{val_accuracy:.2f}.hdf5\", \n",
    "                                           monitor='val_loss', verbose=0, save_best_only=True, mode='auto')\n",
    "es_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, verbose=0, mode='auto')\n",
    "history = model.fit([x_train1, x_train2, x_train3], y_train, epochs=256, batch_size=512, validation_data=([x_test1, x_test2, x_test3], y_test), callbacks=[cp_cb, es_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "# plt.ylim((0, 3.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"../Output/CheckPoint/mag_norm/model0527_14-0.81-0.69-1.54-0.46.hdf5\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_names = ['Still', 'Walking', 'Run', 'Bike', 'Car', 'Bus', 'Train', 'Subway']\n",
    "class_names = [\"Still\", \"Car\", \"Bus\", \"Train\", \"Subway\"]\n",
    "predict = model.predict_classes(X_test)\n",
    "plot_confusion_matrix(Y_test, predict, class_names, False, (16, 8))\n",
    "plt.grid(False)\n",
    "f1_macro = f1_score(Y_test, predict, average='macro')\n",
    "round(f1_macro, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testデータの読み込み→推定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = np.load(\"../Output/test/test_glo_mag_norm_spectram.npy\")[:, :40]\n",
    "test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = np.load(\"../Output/test/test_glo_lacc_norm_spectram.npy\")[:, :64]\n",
    "test2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test3 = np.load(\"../Output/test/test_glo_gyr_norm_spectram.npy\")[:, :64]\n",
    "test3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = test1.reshape([-1, 40, 25, 1])\n",
    "test2 = test2.reshape([-1, 64, 25, 1])\n",
    "test3 = test3.reshape([-1, 64, 25, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = np.argmax(model.predict([test1, test2, test3]), axis=1)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
